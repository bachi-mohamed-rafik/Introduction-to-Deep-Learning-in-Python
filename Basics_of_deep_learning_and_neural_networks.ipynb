{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics of deep learning and neural networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTAjNtsTck0GQSXy/xeqN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachi-mohamed-rafik/Introduction-to-Deep-Learning-in-Python/blob/main/Basics_of_deep_learning_and_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0o5dCUi8CZl",
        "outputId": "b6d0cd9b-2091-41ce-ba4d-7a186c02de78"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_data=np.array([2,3])\n",
        "weights={\n",
        "    'node_0':np.array([1,1]),\n",
        "    'node_1':np.array([-1,1]), \n",
        "    'output':np.array([2,-1])}\n",
        "node_0_value=(input_data * weights['node_0']).sum()\n",
        "node_1_value=(input_data * weights['node_1']).sum()\n",
        "\n",
        "print(\"input_data : \" ,input_data)\n",
        "print(\"node_0_value : \" ,node_0_value)\n",
        "print(\"node_1_value : \",node_1_value)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_data :  [2 3]\n",
            "node_0_value :  5\n",
            "node_1_value :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UYiWoI2CKl6"
      },
      "source": [
        "Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BPz_Dq5CUgf",
        "outputId": "2ee53f95-74aa-43b5-cb03-682fa16d28c3"
      },
      "source": [
        "hidden_layer_values= np.array([node_0_value,node_1_value])\n",
        "print(hidden_layer_values)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2BqQFzhCkj-",
        "outputId": "b6449c5a-86e0-42c1-bed8-0abba2efa61b"
      },
      "source": [
        "output=(hidden_layer_values*weights['output']).sum()\n",
        "print(output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTjtfhRHGuPY"
      },
      "source": [
        "Activation Function:\n",
        "Calculate the value in node 0 by multiplying input_data by its weights weights['node_0'] and computing their sum. This is the 1st node in the hidden layer.\n",
        "Calculate the value in node 1 using input_data and weights['node_1']. This is the 2nd node in the hidden layer.\n",
        "Put the hidden layer values into an array. This has been done for you.\n",
        "Generate the prediction by multiplying hidden_layer_outputs by weights['output'] and computing their sum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSz51Lx6DxvJ",
        "outputId": "19d2f8ff-fc1a-468c-fd1d-9136771f35be"
      },
      "source": [
        "# Calculate node 0 value: node_0_value\n",
        "node_0_value = (input_data * weights['node_0']).sum()\n",
        "\n",
        "# Calculate node 1 value: node_1_value\n",
        "node_1_value = (input_data * weights['node_1']).sum()\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
        "\n",
        "# Calculate output: output\n",
        "output = (hidden_layer_outputs*weights['output']).sum()\n",
        "\n",
        "# Print output\n",
        "print(output)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRr5I80BJku-"
      },
      "source": [
        "Fill in the definition of the relu() function:\n",
        "Use the max() function to calculate the value for the output of relu().\n",
        "Apply the relu() function to node_0_input to calculate node_0_output.\n",
        "Apply the relu() function to node_1_input to calculate node_1_output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61dTagu3JnO_",
        "outputId": "0b2f6260-45a5-480e-df02-a14e473a96ec"
      },
      "source": [
        "def relu(input):\n",
        "    '''Define your relu activation function here'''\n",
        "    # Calculate the value for the output of the relu function: output\n",
        "    output = max(input, 0)\n",
        "    \n",
        "    # Return the value just calculated\n",
        "    return(output)\n",
        "\n",
        "# Calculate node 0 value: node_0_output\n",
        "node_0_input = (input_data * weights['node_0']).sum()\n",
        "node_0_output = relu(node_0_input)\n",
        "\n",
        "# Calculate node 1 value: node_1_output\n",
        "node_1_input = (input_data * weights['node_1']).sum()\n",
        "node_1_output = relu(node_1_input)\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
        "\n",
        "# Calculate model output (do not apply relu)\n",
        "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
        "\n",
        "# Print model output\n",
        "print(model_output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8d9imV_Jpw-",
        "outputId": "cfdd1b3d-2eab-4d5c-b459-d23c2afcd585"
      },
      "source": [
        "input_data=[np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
        "print(input_data)\n",
        "        "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([3, 5]), array([ 1, -1]), array([0, 0]), array([8, 4])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG-6UJBpOArF"
      },
      "source": [
        "Define a function called predict_with_network() that accepts two arguments - input_data_row and weights - and returns a prediction from the network as the output.\n",
        "Calculate the input and output values for each node, storing them as: node_0_input, node_0_output, node_1_input, and node_1_output.\n",
        "To calculate the input value of a node, multiply the relevant arrays together and compute their sum.\n",
        "To calculate the output value of a node, apply the relu() function to the input value of the node.\n",
        "Calculate the model output by calculating input_to_final_layer and model_output in the same way you calculated the input and output values for the nodes.\n",
        "Use a for loop to iterate over input_data:\n",
        "Use your predict_with_network() to generate predictions for each row of the input_data - input_data_row. Append each prediction to results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53e58AvqK9Zk",
        "outputId": "efedf241-7eea-4d53-8176-87118fc8af70"
      },
      "source": [
        "# Define predict_with_network()\n",
        "def predict_with_network(input_data_row, weights):\n",
        "\n",
        "    # Calculate node 0 value\n",
        "    node_0_input = (input_data_row*weights['node_0']).sum()\n",
        "    node_0_output = relu(node_0_input)\n",
        "\n",
        "    # Calculate node 1 value\n",
        "    node_1_input = (input_data_row*weights['node_1']).sum()\n",
        "    node_1_output = relu(node_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_layer_outputs\n",
        "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
        "    \n",
        "    # Calculate model output\n",
        "    input_to_final_layer = (hidden_layer_outputs*weights['output']).sum()\n",
        "    model_output = relu(input_to_final_layer)\n",
        "    \n",
        "    # Return model output\n",
        "    return(model_output)\n",
        "\n",
        "\n",
        "# Create empty list to store prediction results\n",
        "results = []\n",
        "for input_data_row in input_data:\n",
        "    # Append prediction to results\n",
        "    results.append(predict_with_network(input_data_row, weights))\n",
        "\n",
        "# Print results\n",
        "print(results)\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14, 0, 0, 24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZvybvwN_Ih"
      },
      "source": [
        "Calculate node_0_0_input using its weights weights['node_0_0'] and the given input_data. \n",
        "Then apply the relu() function to get node_0_0_output.\n",
        "Do the same as above for node_0_1_input to get node_0_1_output.\n",
        "\n",
        "Calculate node_1_0_input using its weights weights['node_1_0'] and the outputs from the first hidden layer - hidden_0_outputs. Then apply the relu() function to get node_1_0_output.\n",
        "\n",
        "Do the same as above for node_1_1_input to get node_1_1_output.\n",
        "\n",
        "Calculate model_output using its weights weights['output'] and the outputs from the second hidden layer hidden_1_outputs array. Do not apply the relu() function to this output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1b9cCFiZqY6",
        "outputId": "8cb46afd-9691-4e66-bea8-72e31c215def"
      },
      "source": [
        "weights={'output': np.array([2, 7]), 'node_1_0': np.array([-1,  2]), 'node_0_0': np.array([2, 4]), 'node_0_1': np.array([ 4, -5]), 'node_1_1': np.array([1, 2])}\n",
        "input_data=np.array([3,5])\n",
        "def predict_with_network(input_data):\n",
        "    # Calculate node 0 in the first hidden layer\n",
        "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
        "    node_0_0_output = relu(node_0_0_input)\n",
        "\n",
        "    # Calculate node 1 in the first hidden layer\n",
        "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
        "    node_0_1_output = relu(node_0_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_0_outputs\n",
        "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
        "\n",
        "    # Calculate node 0 in the second hidden layer\n",
        "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
        "    node_1_0_output = relu(node_1_0_input)\n",
        "\n",
        "    # Calculate node 1 in the second hidden layer\n",
        "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
        "    node_1_1_output = relu(node_1_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_1_outputs\n",
        "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
        "    \n",
        "    # Calculate output here: model_output\n",
        "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
        "    \n",
        "    # Return model_output\n",
        "    return(model_output)\n",
        "\n",
        "output = predict_with_network(input_data)\n",
        "print(output)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSWUsU8DZsWF"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipa0_ovXZCQ"
      },
      "source": [
        "Coding how weight changes affect accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imds_GbAXcYX"
      },
      "source": [
        "Create a dictionary of weights called weights_1 where you have changed 1 weight from weights_0 (You only need to make 1 edit to weights_0 to generate the perfect prediction).\n",
        "\n",
        "Obtain predictions with the new weights using the predict_with_network() function with input_data and weights_1.\n",
        "\n",
        "Calculate the error for the new weights by subtracting target_actual from model_output_1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2eUrvN0aaUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "20025c5b-02dd-453e-e635-93a1d8a390f6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# The data point you will make a prediction for\n",
        "input_data = np.array([0, 3])\n",
        "\n",
        "# Sample weights\n",
        "weights_0 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 2],\n",
        "             'output': [1, 1]\n",
        "            }\n",
        "\n",
        "# The actual target value, used to calculate the error\n",
        "target_actual = 3\n",
        "\n",
        "# Make prediction using original weights\n",
        "model_output_0 = predict_with_network(input_data, weights_0)\n",
        "\n",
        "# Calculate error: error_0\n",
        "error_0 = model_output_0 - target_actual\n",
        "\n",
        "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
        "weights_1 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 2],\n",
        "             'output': [1, 0]\n",
        "            }\n",
        "\n",
        "\n",
        "# Make prediction using new weights: model_output_1\n",
        "model_output_1 = predict_with_network(input_data, weights_1)\n",
        "\n",
        "\n",
        "# Calculate error: error_1\n",
        "error_1 = model_output_1 - target_actual\n",
        "\n",
        "# Print error_0 and error_1\n",
        "print(error_0)\n",
        "print(error_1)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8daeedcef736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Make prediction using original weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_output_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Calculate error: error_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict_with_network() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "lsxoAAUJXgBy",
        "outputId": "34b5bad3-3af5-425d-90ba-4003ea4b62ab"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create model_output_0 \n",
        "model_output_0 = []\n",
        "# Create model_output_1\n",
        "model_output_1 = []\n",
        "\n",
        "# Loop over input_data\n",
        "for row in input_data:\n",
        "    # Append prediction to model_output_0\n",
        "    model_output_0.append(predict_with_network(row, weights_0))\n",
        "    \n",
        "    # Append prediction to model_output_1\n",
        "    model_output_1.append(predict_with_network(row, weights_1))\n",
        "\n",
        "# Calculate the mean squared error for model_output_0: mse_0\n",
        "mse_0 = mean_squared_error(target_actuals, model_output_0)\n",
        "\n",
        "# Calculate the mean squared error for model_output_1: mse_1\n",
        "mse_1 = mean_squared_error(target_actuals, model_output_1)\n",
        "\n",
        "# Print mse_0 and mse_1\n",
        "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
        "print(\"Mean squared error with weights_1: %f\" %mse_1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c695c879cc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Append prediction to model_output_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel_output_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_with_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Append prediction to model_output_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict_with_network() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xps_ugPRbfpr",
        "outputId": "39fc6184-ac63-4409-faec-cd527f66240e"
      },
      "source": [
        "weights=np.array([0,2,1])\n",
        "input_data=np.array([1,2,3])\n",
        "target = 0\n",
        "\n",
        "# Calculate the predictions: preds\n",
        "preds = (weights*input_data).sum()\n",
        "\n",
        "# Calculate the error: error\n",
        "error = preds - target\n",
        "\n",
        "# Calculate the slope: slope\n",
        "slope = 2 * input_data * error\n",
        "\n",
        "# Print the slope\n",
        "print(slope)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14 28 42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlgOWJ5CerWk",
        "outputId": "75f63bf5-f265-4853-d69c-ebef73a2b378"
      },
      "source": [
        "# Set the learning rate: learning_rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Calculate the predictions: preds\n",
        "preds = (weights * input_data).sum()\n",
        "\n",
        "# Calculate the error: error\n",
        "error = preds - target\n",
        "\n",
        "# Calculate the slope: slope\n",
        "slope = 2 * input_data * error\n",
        "\n",
        "# Update the weights: weights_updated\n",
        "weights_updated = weights-(learning_rate*slope)\n",
        "\n",
        "# Get updated predictions: preds_updated\n",
        "preds_updated = (weights_updated*input_data).sum()\n",
        "\n",
        "# Calculate updated error: error_updated\n",
        "error_updated = preds_updated-target\n",
        "\n",
        "# Print the original error\n",
        "print(error)\n",
        "\n",
        "# Print the updated error\n",
        "print(error_updated)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "5.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPN061f_haA4"
      },
      "source": [
        "n_updates = 20\n",
        "mse_hist = []\n",
        "\n",
        "# Iterate over the number of updates\n",
        "for i in range(n_updates):\n",
        "    # Calculate the slope: slope\n",
        "    slope = get_slope(input_data, target, weights)\n",
        "    \n",
        "    # Update the weights: weights\n",
        "    weights = weights - 0.01 * slope\n",
        "    \n",
        "    # Calculate mse with new weights: mse\n",
        "    mse = get_mse(input_data, target, weights)\n",
        "    \n",
        "    # Append the mse to mse_hist\n",
        "    mse_hist.append(mse)\n",
        "\n",
        "# Plot the mse history\n",
        "plt.plot(mse_hist)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpT0hvvTkSKZ"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Specify the model\n",
        "n_cols = predictors.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "# Verify that model contains information from compiling\n",
        "print(predictors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xjjkFw1_SoB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uIedNo5_rB1"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Specify the model\n",
        "n_cols = predictors.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors,target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpr2vXcsGi8W"
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(df.survived)\n",
        "\n",
        "# Set up the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors,target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18h8aSv2IPZJ"
      },
      "source": [
        "# Specify, compile, and fit the model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(predictors, target)\n",
        "\n",
        "# Calculate predictions: predictions\n",
        "predictions = model.predict(pred_data)\n",
        "\n",
        "# Calculate predicted probability of survival: predicted_prob_true\n",
        "predicted_prob_true = predictions[:,1]\n",
        "\n",
        "# print predicted_prob_true\n",
        "print(predicted_prob_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LarNDeMMJrW"
      },
      "source": [
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(predictors, target, validation_split=0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnkAomRWMK1L"
      },
      "source": [
        "# Import EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyU9O8y9dbGd"
      },
      "source": [
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first and second layers\n",
        "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model_1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model_2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi4KKbjPiObV"
      },
      "source": [
        "# The input shape to use in the first hidden layer\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first, second, and third hidden layers\n",
        "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model 1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model 2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p7JwQlmnZCS"
      },
      "source": [
        "# Create the model: model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first hidden layer\n",
        "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Add the second hidden layer\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, validation_split=0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}